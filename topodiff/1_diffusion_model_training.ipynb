{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b63a336",
   "metadata": {},
   "source": [
    "# 3D TPMS Diffusion model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83534315",
   "metadata": {},
   "source": [
    "#### 학습 진행 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a22e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./checkpoints/3d_diff_logdir_optimized_final\n",
      "Creating model and diffusion...\n",
      "Model parameters: 58,794,114 total, 58,794,114 trainable\n",
      "Model size: 224.3 MB (fp32)\n",
      "Input shape: [batch_size, 1, 64, 64, 64]\n",
      "Output channels: 2\n",
      "Creating data loader...\n",
      "Testing data loading...\n",
      "Loading 5597 files for training\n",
      "VolumeDataset initialized with 5597 volumes, target resolution: 64\n",
      "Loaded test batch: shape=torch.Size([4, 1, 64, 64, 64]), range=[-1.000, 1.000], mean=-0.414\n",
      "Starting training...\n",
      "----------------------------\n",
      "| grad_norm     | 11.7     |\n",
      "| lg_loss_scale | 20       |\n",
      "| loss          | 1.01     |\n",
      "| mse           | 1        |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 4        |\n",
      "| step          | 0        |\n",
      "| vb            | 0.0111   |\n",
      "----------------------------\n",
      "saving model 0...\n",
      "saving model 0.9999...\n",
      "----------------------------\n",
      "| grad_norm     | 13.3     |\n",
      "| lg_loss_scale | 20       |\n",
      "| loss          | 0.945    |\n",
      "| mse           | 0.933    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 44       |\n",
      "| step          | 10       |\n",
      "| vb            | 0.0121   |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 13.3     |\n",
      "| lg_loss_scale | 20       |\n",
      "| loss          | 0.798    |\n",
      "| mse           | 0.789    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 84       |\n",
      "| step          | 20       |\n",
      "| vb            | 0.00854  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 11.6     |\n",
      "| lg_loss_scale | 20       |\n",
      "| loss          | 0.671    |\n",
      "| mse           | 0.661    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 124      |\n",
      "| step          | 30       |\n",
      "| vb            | 0.00986  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 10.8     |\n",
      "| lg_loss_scale | 20       |\n",
      "| loss          | 9.41     |\n",
      "| mse           | 0.534    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 164      |\n",
      "| step          | 40       |\n",
      "| vb            | 8.88     |\n",
      "----------------------------\n",
      "Found NaN, decreased lg_loss_scale to 19.045000000000055\n",
      "----------------------------\n",
      "| grad_norm     | 9.69     |\n",
      "| lg_loss_scale | 19.5     |\n",
      "| loss          | 0.429    |\n",
      "| mse           | 0.424    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 204      |\n",
      "| step          | 50       |\n",
      "| vb            | 0.00534  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 8.59     |\n",
      "| lg_loss_scale | 19.1     |\n",
      "| loss          | 0.422    |\n",
      "| mse           | 0.353    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 244      |\n",
      "| step          | 60       |\n",
      "| vb            | 0.0691   |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 7.34     |\n",
      "| lg_loss_scale | 19.1     |\n",
      "| loss          | 0.263    |\n",
      "| mse           | 0.259    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 284      |\n",
      "| step          | 70       |\n",
      "| vb            | 0.00429  |\n",
      "----------------------------\n",
      "Found NaN, decreased lg_loss_scale to 18.07400000000009\n",
      "----------------------------\n",
      "| grad_norm     | 6.6      |\n",
      "| lg_loss_scale | 18.6     |\n",
      "| loss          | 0.228    |\n",
      "| mse           | 0.219    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 324      |\n",
      "| step          | 80       |\n",
      "| vb            | 0.00857  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 5.69     |\n",
      "| lg_loss_scale | 18.1     |\n",
      "| loss          | 0.177    |\n",
      "| mse           | 0.174    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 364      |\n",
      "| step          | 90       |\n",
      "| vb            | 0.00275  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 4.57     |\n",
      "| lg_loss_scale | 18.1     |\n",
      "| loss          | 0.124    |\n",
      "| mse           | 0.122    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 404      |\n",
      "| step          | 100      |\n",
      "| vb            | 0.0023   |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 3.81     |\n",
      "| lg_loss_scale | 18.1     |\n",
      "| loss          | 0.0976   |\n",
      "| mse           | 0.0921   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 444      |\n",
      "| step          | 110      |\n",
      "| vb            | 0.0055   |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 3.93     |\n",
      "| lg_loss_scale | 18.1     |\n",
      "| loss          | 0.0909   |\n",
      "| mse           | 0.0861   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 484      |\n",
      "| step          | 120      |\n",
      "| vb            | 0.00481  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 2.79     |\n",
      "| lg_loss_scale | 18.1     |\n",
      "| loss          | 0.0669   |\n",
      "| mse           | 0.0662   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 524      |\n",
      "| step          | 130      |\n",
      "| vb            | 0.000661 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 2.08     |\n",
      "| lg_loss_scale | 18.1     |\n",
      "| loss          | 0.0518   |\n",
      "| mse           | 0.051    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 564      |\n",
      "| step          | 140      |\n",
      "| vb            | 0.000847 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 3.93     |\n",
      "| lg_loss_scale | 18.1     |\n",
      "| loss          | 0.0688   |\n",
      "| mse           | 0.067    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 604      |\n",
      "| step          | 150      |\n",
      "| vb            | 0.00175  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 2.49     |\n",
      "| lg_loss_scale | 18.2     |\n",
      "| loss          | 0.0559   |\n",
      "| mse           | 0.0548   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 644      |\n",
      "| step          | 160      |\n",
      "| vb            | 0.0011   |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 2.28     |\n",
      "| lg_loss_scale | 18.2     |\n",
      "| loss          | 0.0685   |\n",
      "| mse           | 0.0618   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 684      |\n",
      "| step          | 170      |\n",
      "| vb            | 0.00674  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 1.35     |\n",
      "| lg_loss_scale | 18.2     |\n",
      "| loss          | 0.0409   |\n",
      "| mse           | 0.0404   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 724      |\n",
      "| step          | 180      |\n",
      "| vb            | 0.000512 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 1.04     |\n",
      "| lg_loss_scale | 18.2     |\n",
      "| loss          | 0.0382   |\n",
      "| mse           | 0.0376   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 764      |\n",
      "| step          | 190      |\n",
      "| vb            | 0.000586 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 1.03     |\n",
      "| lg_loss_scale | 18.2     |\n",
      "| loss          | 0.0369   |\n",
      "| mse           | 0.036    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 804      |\n",
      "| step          | 200      |\n",
      "| vb            | 0.000873 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.767    |\n",
      "| lg_loss_scale | 18.2     |\n",
      "| loss          | 0.0285   |\n",
      "| mse           | 0.0281   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 844      |\n",
      "| step          | 210      |\n",
      "| vb            | 0.000309 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.836    |\n",
      "| lg_loss_scale | 18.2     |\n",
      "| loss          | 0.0318   |\n",
      "| mse           | 0.0313   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 884      |\n",
      "| step          | 220      |\n",
      "| vb            | 0.000508 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.734    |\n",
      "| lg_loss_scale | 18.2     |\n",
      "| loss          | 0.0281   |\n",
      "| mse           | 0.0276   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 924      |\n",
      "| step          | 230      |\n",
      "| vb            | 0.000485 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.648    |\n",
      "| lg_loss_scale | 18.2     |\n",
      "| loss          | 0.0275   |\n",
      "| mse           | 0.0271   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 964      |\n",
      "| step          | 240      |\n",
      "| vb            | 0.000447 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 1.35     |\n",
      "| lg_loss_scale | 18.2     |\n",
      "| loss          | 0.0785   |\n",
      "| mse           | 0.0418   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1e+03    |\n",
      "| step          | 250      |\n",
      "| vb            | 0.0367   |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.963    |\n",
      "| lg_loss_scale | 18.3     |\n",
      "| loss          | 0.0364   |\n",
      "| mse           | 0.0349   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.04e+03 |\n",
      "| step          | 260      |\n",
      "| vb            | 0.00149  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.618    |\n",
      "| lg_loss_scale | 18.3     |\n",
      "| loss          | 0.0228   |\n",
      "| mse           | 0.0224   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.08e+03 |\n",
      "| step          | 270      |\n",
      "| vb            | 0.000428 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.626    |\n",
      "| lg_loss_scale | 18.3     |\n",
      "| loss          | 0.0201   |\n",
      "| mse           | 0.0198   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.12e+03 |\n",
      "| step          | 280      |\n",
      "| vb            | 0.000257 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.876    |\n",
      "| lg_loss_scale | 18.3     |\n",
      "| loss          | 0.0248   |\n",
      "| mse           | 0.0241   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.16e+03 |\n",
      "| step          | 290      |\n",
      "| vb            | 0.000717 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.556    |\n",
      "| lg_loss_scale | 18.3     |\n",
      "| loss          | 0.0229   |\n",
      "| mse           | 0.0222   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.2e+03  |\n",
      "| step          | 300      |\n",
      "| vb            | 0.000685 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.681    |\n",
      "| lg_loss_scale | 18.3     |\n",
      "| loss          | 0.0216   |\n",
      "| mse           | 0.0212   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.24e+03 |\n",
      "| step          | 310      |\n",
      "| vb            | 0.000425 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.413    |\n",
      "| lg_loss_scale | 18.3     |\n",
      "| loss          | 0.015    |\n",
      "| mse           | 0.0148   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.28e+03 |\n",
      "| step          | 320      |\n",
      "| vb            | 0.000174 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.514    |\n",
      "| lg_loss_scale | 18.3     |\n",
      "| loss          | 0.0186   |\n",
      "| mse           | 0.0181   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.32e+03 |\n",
      "| step          | 330      |\n",
      "| vb            | 0.000548 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.662    |\n",
      "| lg_loss_scale | 18.3     |\n",
      "| loss          | 0.0233   |\n",
      "| mse           | 0.0227   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.36e+03 |\n",
      "| step          | 340      |\n",
      "| vb            | 0.000645 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.355    |\n",
      "| lg_loss_scale | 18.3     |\n",
      "| loss          | 0.0165   |\n",
      "| mse           | 0.0161   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.4e+03  |\n",
      "| step          | 350      |\n",
      "| vb            | 0.000398 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.262    |\n",
      "| lg_loss_scale | 18.4     |\n",
      "| loss          | 0.0135   |\n",
      "| mse           | 0.0133   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.44e+03 |\n",
      "| step          | 360      |\n",
      "| vb            | 0.000181 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.392    |\n",
      "| lg_loss_scale | 18.4     |\n",
      "| loss          | 0.0203   |\n",
      "| mse           | 0.0199   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.48e+03 |\n",
      "| step          | 370      |\n",
      "| vb            | 0.000406 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.277    |\n",
      "| lg_loss_scale | 18.4     |\n",
      "| loss          | 0.144    |\n",
      "| mse           | 0.0124   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.52e+03 |\n",
      "| step          | 380      |\n",
      "| vb            | 0.131    |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.302    |\n",
      "| lg_loss_scale | 18.4     |\n",
      "| loss          | 0.0174   |\n",
      "| mse           | 0.017    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.56e+03 |\n",
      "| step          | 390      |\n",
      "| vb            | 0.000397 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.296    |\n",
      "| lg_loss_scale | 18.4     |\n",
      "| loss          | 0.0145   |\n",
      "| mse           | 0.0141   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.6e+03  |\n",
      "| step          | 400      |\n",
      "| vb            | 0.000321 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.197    |\n",
      "| lg_loss_scale | 18.4     |\n",
      "| loss          | 0.0112   |\n",
      "| mse           | 0.0111   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.64e+03 |\n",
      "| step          | 410      |\n",
      "| vb            | 0.00015  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.765    |\n",
      "| lg_loss_scale | 18.4     |\n",
      "| loss          | 0.0672   |\n",
      "| mse           | 0.0298   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.68e+03 |\n",
      "| step          | 420      |\n",
      "| vb            | 0.0373   |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.726    |\n",
      "| lg_loss_scale | 18.4     |\n",
      "| loss          | 0.022    |\n",
      "| mse           | 0.0214   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.72e+03 |\n",
      "| step          | 430      |\n",
      "| vb            | 0.000639 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.339    |\n",
      "| lg_loss_scale | 18.4     |\n",
      "| loss          | 0.0171   |\n",
      "| mse           | 0.0168   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.76e+03 |\n",
      "| step          | 440      |\n",
      "| vb            | 0.00029  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.301    |\n",
      "| lg_loss_scale | 18.4     |\n",
      "| loss          | 0.0124   |\n",
      "| mse           | 0.0123   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.8e+03  |\n",
      "| step          | 450      |\n",
      "| vb            | 0.000142 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.318    |\n",
      "| lg_loss_scale | 18.5     |\n",
      "| loss          | 0.0164   |\n",
      "| mse           | 0.0161   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.84e+03 |\n",
      "| step          | 460      |\n",
      "| vb            | 0.000328 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.312    |\n",
      "| lg_loss_scale | 18.5     |\n",
      "| loss          | 0.0116   |\n",
      "| mse           | 0.0115   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.88e+03 |\n",
      "| step          | 470      |\n",
      "| vb            | 0.000171 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.423    |\n",
      "| lg_loss_scale | 18.5     |\n",
      "| loss          | 0.0209   |\n",
      "| mse           | 0.0201   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.92e+03 |\n",
      "| step          | 480      |\n",
      "| vb            | 0.000819 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.203    |\n",
      "| lg_loss_scale | 18.5     |\n",
      "| loss          | 0.0118   |\n",
      "| mse           | 0.0116   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 1.96e+03 |\n",
      "| step          | 490      |\n",
      "| vb            | 0.000245 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.343    |\n",
      "| lg_loss_scale | 18.5     |\n",
      "| loss          | 0.0161   |\n",
      "| mse           | 0.0152   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2e+03    |\n",
      "| step          | 500      |\n",
      "| vb            | 0.0009   |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.678    |\n",
      "| lg_loss_scale | 18.5     |\n",
      "| loss          | 0.0175   |\n",
      "| mse           | 0.0164   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.04e+03 |\n",
      "| step          | 510      |\n",
      "| vb            | 0.00112  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.444    |\n",
      "| lg_loss_scale | 18.5     |\n",
      "| loss          | 0.0158   |\n",
      "| mse           | 0.0155   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.08e+03 |\n",
      "| step          | 520      |\n",
      "| vb            | 0.000302 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.515    |\n",
      "| lg_loss_scale | 18.5     |\n",
      "| loss          | 0.0231   |\n",
      "| mse           | 0.0217   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.12e+03 |\n",
      "| step          | 530      |\n",
      "| vb            | 0.00141  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.476    |\n",
      "| lg_loss_scale | 18.5     |\n",
      "| loss          | 0.0178   |\n",
      "| mse           | 0.0169   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.16e+03 |\n",
      "| step          | 540      |\n",
      "| vb            | 0.000839 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.424    |\n",
      "| lg_loss_scale | 18.5     |\n",
      "| loss          | 0.0147   |\n",
      "| mse           | 0.0142   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.2e+03  |\n",
      "| step          | 550      |\n",
      "| vb            | 0.000507 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.427    |\n",
      "| lg_loss_scale | 18.6     |\n",
      "| loss          | 0.0179   |\n",
      "| mse           | 0.0167   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.24e+03 |\n",
      "| step          | 560      |\n",
      "| vb            | 0.00118  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.34     |\n",
      "| lg_loss_scale | 18.6     |\n",
      "| loss          | 0.113    |\n",
      "| mse           | 0.0128   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.28e+03 |\n",
      "| step          | 570      |\n",
      "| vb            | 0.101    |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.26     |\n",
      "| lg_loss_scale | 18.6     |\n",
      "| loss          | 0.0126   |\n",
      "| mse           | 0.0124   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.32e+03 |\n",
      "| step          | 580      |\n",
      "| vb            | 0.000168 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.244    |\n",
      "| lg_loss_scale | 18.6     |\n",
      "| loss          | 0.0139   |\n",
      "| mse           | 0.0136   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.36e+03 |\n",
      "| step          | 590      |\n",
      "| vb            | 0.000328 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.192    |\n",
      "| lg_loss_scale | 18.6     |\n",
      "| loss          | 0.0114   |\n",
      "| mse           | 0.0112   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.4e+03  |\n",
      "| step          | 600      |\n",
      "| vb            | 0.000175 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.24     |\n",
      "| lg_loss_scale | 18.6     |\n",
      "| loss          | 0.0116   |\n",
      "| mse           | 0.0114   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.44e+03 |\n",
      "| step          | 610      |\n",
      "| vb            | 0.000206 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.242    |\n",
      "| lg_loss_scale | 18.6     |\n",
      "| loss          | 0.0126   |\n",
      "| mse           | 0.0123   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.48e+03 |\n",
      "| step          | 620      |\n",
      "| vb            | 0.00026  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.201    |\n",
      "| lg_loss_scale | 18.6     |\n",
      "| loss          | 0.0113   |\n",
      "| mse           | 0.0111   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.52e+03 |\n",
      "| step          | 630      |\n",
      "| vb            | 0.000153 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.246    |\n",
      "| lg_loss_scale | 18.6     |\n",
      "| loss          | 0.107    |\n",
      "| mse           | 0.014    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.56e+03 |\n",
      "| step          | 640      |\n",
      "| vb            | 0.093    |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.375    |\n",
      "| lg_loss_scale | 18.6     |\n",
      "| loss          | 0.0159   |\n",
      "| mse           | 0.0155   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.6e+03  |\n",
      "| step          | 650      |\n",
      "| vb            | 0.000454 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.786    |\n",
      "| lg_loss_scale | 18.7     |\n",
      "| loss          | 0.0543   |\n",
      "| mse           | 0.0235   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.64e+03 |\n",
      "| step          | 660      |\n",
      "| vb            | 0.0309   |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.308    |\n",
      "| lg_loss_scale | 18.7     |\n",
      "| loss          | 0.012    |\n",
      "| mse           | 0.0117   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.68e+03 |\n",
      "| step          | 670      |\n",
      "| vb            | 0.000234 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.706    |\n",
      "| lg_loss_scale | 18.7     |\n",
      "| loss          | 0.0672   |\n",
      "| mse           | 0.0331   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.72e+03 |\n",
      "| step          | 680      |\n",
      "| vb            | 0.0341   |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.251    |\n",
      "| lg_loss_scale | 18.7     |\n",
      "| loss          | 0.0119   |\n",
      "| mse           | 0.0117   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.76e+03 |\n",
      "| step          | 690      |\n",
      "| vb            | 0.000113 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.573    |\n",
      "| lg_loss_scale | 18.7     |\n",
      "| loss          | 0.0249   |\n",
      "| mse           | 0.0221   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.8e+03  |\n",
      "| step          | 700      |\n",
      "| vb            | 0.00272  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.404    |\n",
      "| lg_loss_scale | 18.7     |\n",
      "| loss          | 0.0169   |\n",
      "| mse           | 0.0164   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.84e+03 |\n",
      "| step          | 710      |\n",
      "| vb            | 0.000539 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.343    |\n",
      "| lg_loss_scale | 18.7     |\n",
      "| loss          | 0.0185   |\n",
      "| mse           | 0.0176   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.88e+03 |\n",
      "| step          | 720      |\n",
      "| vb            | 0.000891 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.212    |\n",
      "| lg_loss_scale | 18.7     |\n",
      "| loss          | 0.0125   |\n",
      "| mse           | 0.0123   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.92e+03 |\n",
      "| step          | 730      |\n",
      "| vb            | 0.000157 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.244    |\n",
      "| lg_loss_scale | 18.7     |\n",
      "| loss          | 0.0113   |\n",
      "| mse           | 0.0111   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 2.96e+03 |\n",
      "| step          | 740      |\n",
      "| vb            | 0.000185 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.229    |\n",
      "| lg_loss_scale | 18.7     |\n",
      "| loss          | 0.0155   |\n",
      "| mse           | 0.015    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 3e+03    |\n",
      "| step          | 750      |\n",
      "| vb            | 0.000477 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.502    |\n",
      "| lg_loss_scale | 18.8     |\n",
      "| loss          | 0.0277   |\n",
      "| mse           | 0.0238   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 3.04e+03 |\n",
      "| step          | 760      |\n",
      "| vb            | 0.00387  |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.319    |\n",
      "| lg_loss_scale | 18.8     |\n",
      "| loss          | 0.0127   |\n",
      "| mse           | 0.0125   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 3.08e+03 |\n",
      "| step          | 770      |\n",
      "| vb            | 0.000183 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.224    |\n",
      "| lg_loss_scale | 18.8     |\n",
      "| loss          | 0.0118   |\n",
      "| mse           | 0.0116   |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 3.12e+03 |\n",
      "| step          | 780      |\n",
      "| vb            | 0.000174 |\n",
      "----------------------------\n",
      "----------------------------\n",
      "| grad_norm     | 0.209    |\n",
      "| lg_loss_scale | 18.8     |\n",
      "| loss          | 0.134    |\n",
      "| mse           | 0.013    |\n",
      "| param_norm    | 139      |\n",
      "| samples       | 3.16e+03 |\n",
      "| step          | 790      |\n",
      "| vb            | 0.121    |\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TOPODIFF_LOGDIR'] = './checkpoints/3d_diff_logdir_optimized_final'\n",
    "\n",
    "# 최적화된 학습 파라미터\n",
    "TRAIN_FLAGS = \"\"\"\n",
    "--batch_size 4\n",
    "--save_interval 1000 \n",
    "--use_fp16 True \n",
    "--lr 5e-5 \n",
    "--weight_decay 0.01\n",
    "--ema_rate 0.9999\n",
    "--log_interval 10\n",
    "--microbatch 2\n",
    "--schedule_sampler uniform\n",
    "--resume_checkpoint \"\"\n",
    "--num_workers 4\n",
    "\"\"\"\n",
    "\n",
    "# 3D에 최적화된 모델 파라미터\n",
    "MODEL_FLAGS = \"\"\"\n",
    "--image_size 64 \n",
    "--num_channels 64\n",
    "--num_res_blocks 2 \n",
    "--learn_sigma True \n",
    "--dropout 0.1 \n",
    "--use_checkpoint True\n",
    "--attention_resolutions 16,8\n",
    "--channel_mult 1,2,3,4\n",
    "--use_scale_shift_norm True\n",
    "--resblock_updown False\n",
    "--dims 3\n",
    "--in_channels 1\n",
    "\"\"\"\n",
    "\n",
    "# Diffusion 파라미터\n",
    "DIFFUSION_FLAGS = \"\"\"\n",
    "--diffusion_steps 1000 \n",
    "--noise_schedule cosine\n",
    "--use_kl False\n",
    "--predict_xstart False\n",
    "--rescale_timesteps False\n",
    "\"\"\"\n",
    "\n",
    "# 데이터 경로\n",
    "DATA_FLAGS = \"--data_dir /home/yeoneung/Euihyun/3D_TPMS_topoDIff/data\"\n",
    "\n",
    "# 실행\n",
    "%run scripts/image_train.py $MODEL_FLAGS $DIFFUSION_FLAGS $TRAIN_FLAGS $DATA_FLAGS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topodiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
